# =============================================================================
# EvalForge Environment Configuration
# =============================================================================
# This file documents ALL environment variables used across EvalForge services.
# Copy to .env and fill in your values: cp .env.example .env
#
# Structure:
#   1. GCP / Infrastructure (shared across all services)
#   2. Firestore Configuration
#   3. Ingestion Service (Datadog)
#   4. Extraction Service (Vertex AI Gemini)
#   5. Deduplication Service (Vertex AI Embeddings)
#   6. Eval Test Generator Service (Vertex AI Gemini)
#   7. Deployment / Scheduling
#   8. Testing / Development
# =============================================================================


# =============================================================================
# 1. GCP / INFRASTRUCTURE (Required for all services)
# =============================================================================

# GCP Project ID - used by all services
# Required for: All services, deployment scripts
GOOGLE_CLOUD_PROJECT="your-gcp-project-id"

# Path to service account JSON (optional if using gcloud auth application-default login)
# Required for: Production deployments, CI/CD
# GOOGLE_APPLICATION_CREDENTIALS="/absolute/path/to/service-account.json"

# Vertex AI Configuration (shared by Extraction and Deduplication services)
# Default: us-central1 (from src/common/config.py:105)
VERTEX_AI_PROJECT="${GOOGLE_CLOUD_PROJECT}"
VERTEX_AI_LOCATION="us-central1"


# =============================================================================
# 2. FIRESTORE CONFIGURATION
# =============================================================================

# Collection prefix for all Firestore collections
# Default: "evalforge_" (from src/common/config.py:146)
FIRESTORE_COLLECTION_PREFIX="evalforge_"

# Firestore database ID
# Default: "(default)" for default database
# Production: "evalforge" (named database)
# Source: src/common/config.py:148, docker-compose.yml
FIRESTORE_DATABASE_ID="(default)"

# Firestore Emulator (for local development only)
# Uncomment when running against a local emulator
# FIRESTORE_EMULATOR_HOST="localhost:8086"


# =============================================================================
# 3. INGESTION SERVICE (Datadog Integration)
# =============================================================================

# Datadog API credentials (REQUIRED for ingestion service)
# Get from: https://app.datadoghq.com/organization-settings/api-keys
DATADOG_API_KEY="replace-with-datadog-api-key"

# Get from: https://app.datadoghq.com/organization-settings/application-keys
DATADOG_APP_KEY="replace-with-datadog-app-key"

# Datadog site/region
# Options: datadoghq.com (US1), us3.datadoghq.com (US3), us5.datadoghq.com (US5),
#          datadoghq.eu (EU), ap1.datadoghq.com (AP1), ddog-gov.com (US1-FED)
# Default: "datadoghq.com" (from src/common/config.py:139)
# Note: deploy.sh uses "us5.datadoghq.com"
DATADOG_SITE="datadoghq.com"

# How far back to look for traces (hours)
# Default: 24 (from src/common/config.py:140)
TRACE_LOOKBACK_HOURS=24

# Minimum quality score threshold for capturing traces
# Default: 0.5 (from src/common/config.py:141)
# Note: docker-compose.yml uses 0.3 for local dev
QUALITY_THRESHOLD=0.5

# Maximum sleep time (seconds) when rate limited by Datadog
# Default: 10 (from src/common/config.py:142)
DATADOG_RATE_LIMIT_MAX_SLEEP=10

# Salt for PII hashing (user IDs, etc.)
# IMPORTANT: Use a strong, unique value in production
PII_SALT="change-me-for-prod"

# Latency buffer (minutes) to avoid fetching in-flight traces
# Used by: deploy.sh
# Default: 5
INGESTION_LATENCY_MINUTES=5


# =============================================================================
# 4. EXTRACTION SERVICE (Vertex AI Gemini)
# =============================================================================

# Gemini model for failure pattern extraction
# Default: "gemini-2.5-flash" (from src/common/config.py:102)
# Note: docker-compose.yml uses "gemini-2.0-flash"
GEMINI_MODEL="gemini-2.5-flash"

# Model temperature (lower = more deterministic)
# Default: 0.2 (from src/common/config.py:103)
GEMINI_TEMPERATURE=0.2

# Maximum output tokens per extraction
# Default: 4096 (from src/common/config.py:104)
GEMINI_MAX_OUTPUT_TOKENS=4096

# Batch size for extraction processing
# Default: 50 (from src/common/config.py:108)
# Note: docker-compose.yml uses 5 for local dev
BATCH_SIZE=50

# Timeout per trace extraction (seconds)
# Default: 10.0 (from src/common/config.py:109)
PER_TRACE_TIMEOUT_SEC=10.0


# =============================================================================
# 5. DEDUPLICATION SERVICE (Vertex AI Embeddings)
# =============================================================================

# Embedding model for semantic similarity
# Default: "text-embedding-004" (from src/common/config.py:204)
EMBEDDING_MODEL="text-embedding-004"

# Embedding output dimensionality
# Default: 768 (from src/common/config.py:216)
EMBEDDING_DIMENSIONALITY=768

# Cosine similarity threshold for deduplication
# Patterns with similarity >= threshold are merged
# Default: 0.85 (from src/common/config.py:203)
SIMILARITY_THRESHOLD=0.85

# Batch size for deduplication processing
# Default: 20 (from src/common/config.py:205)
DEDUP_BATCH_SIZE=20

# Polling interval between deduplication runs (seconds)
# Default: 300 (5 minutes) (from src/common/config.py:206)
DEDUP_POLL_INTERVAL_SECONDS=300


# =============================================================================
# 6. EVAL TEST GENERATOR SERVICE (Vertex AI Gemini)
# =============================================================================

# Batch size for eval test draft generation
# Default: 20
EVAL_TEST_BATCH_SIZE=20

# Timeout per suggestion generation (seconds)
# Default: 30.0
EVAL_TEST_PER_SUGGESTION_TIMEOUT_SEC=30.0

# Cost budget (USD) per suggestion (best-effort estimate; used for run budget enforcement)
# Default: 0.10
EVAL_TEST_COST_BUDGET_USD_PER_SUGGESTION=0.10

# Optional: total run budget override (USD). If unset, derived from batch size * per-suggestion budget.
# Default: unset
# EVAL_TEST_RUN_COST_BUDGET_USD=2.00

# Optional: override max output tokens for eval test generation (defaults to GEMINI_MAX_OUTPUT_TOKENS)
# Default: unset
# EVAL_TEST_MAX_OUTPUT_TOKENS=2048


# =============================================================================
# 7. DEPLOYMENT / SCHEDULING (Cloud Run & Cloud Scheduler)
# =============================================================================

# These are used by deployment scripts, not by the services directly

# GCP Region for Cloud Run deployment
# Default: us-central1 (from scripts/deploy.sh:71)
GCP_REGION="us-central1"

# Ingestion service Cloud Scheduler cron schedule
# Default: "*/5 * * * *" (every 5 minutes) (from scripts/deploy.sh:74)
INGESTION_SCHEDULE="*/5 * * * *"

# Extraction service Cloud Scheduler cron schedule
# Default: "*/30 * * * *" (every 30 minutes) (from scripts/deploy_extraction_scheduler.sh:26)
EXTRACTION_SCHEDULE="*/30 * * * *"

# Deduplication service Cloud Scheduler cron schedule
# Default: "*/5 * * * *" (every 5 minutes) (from scripts/deploy_deduplication.sh:73)
DEDUP_SCHEDULE="*/5 * * * *"

# Skip Cloud Scheduler setup during deployment
# Set to 1 to deploy without scheduler (manual triggers only)
SKIP_SCHEDULER=0


# =============================================================================
# 8. TESTING / DEVELOPMENT
# =============================================================================

# Enable live integration tests (requires real credentials)
# Set to 1 to run tests against live Datadog/Firestore/Vertex AI
# Default: 0 (from .env.example)
RUN_LIVE_TESTS=0

# Collection prefix for integration tests (avoids polluting production data)
# Default: "ci"
LIVE_TEST_COLLECTION_PREFIX="ci"

# Tolerance for capture timestamp validation (minutes)
# Default: 15
LIVE_TEST_CAPTURE_TOLERANCE_MINUTES=15

# Export destination for test data
# Default: "eval_backlog"
LIVE_TEST_EXPORT_DESTINATION="eval_backlog"

# Container port (automatically set by Cloud Run, rarely needs override)
# Default: 8080 (from Dockerfile)
# PORT=8080


# =============================================================================
# QUICK REFERENCE: Required vs Optional
# =============================================================================
#
# REQUIRED (no defaults, must be set):
#   - GOOGLE_CLOUD_PROJECT    (for all services)
#   - DATADOG_API_KEY         (for ingestion only)
#   - DATADOG_APP_KEY         (for ingestion only)
#   - PII_SALT                (for ingestion, should be unique per environment)
#
# OPTIONAL (have sensible defaults):
#   - All other variables have defaults in src/common/config.py
#   - Deployment scripts have their own defaults
#
# PER-ENVIRONMENT OVERRIDES:
#   - Local dev: Lower QUALITY_THRESHOLD, smaller BATCH_SIZE
#   - Production: Use named Firestore database (FIRESTORE_DATABASE_ID=evalforge)
#   - CI/CD: Set RUN_LIVE_TESTS=1, use LIVE_TEST_COLLECTION_PREFIX
#
# =============================================================================
